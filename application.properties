#File Updated
#Fri Apr 01 12:55:49 CEST 2022
# hole text corpus at once
every.single.sentence=false
# how many sections (Bezirke) of a address are accepted 
max.section.count=2
geonames.uri=api.geonames.org
# label name
node.ontology=Ontology
neo4j.password=password
# center distance calculation 
origin.location.latitude=52.530644d
# which KeywordExtractor
keyword.extractor.algorithms=de.citytwin.algorithm.keywords.TFIDFKeywordExtractor,de.citytwin.algorithm.keywords.TextRankKeywordExtractor
# which normalization calculation (equation) to avoid number overflow (none, log or double)
normalization=none
# geonames api parameter, count of max row results 
geonames.maxrows=10
# threshold of a single named.entity (Pois) length (String.length) 
min.named.entity.length=5
path.2.alkis.catalog.file=D\:\\VMS\\catalogs\\alkis_catalog.json
# label name
edge.affect=affect
# file name (here relative)
path.2.postgreSQL.propertiy.file=postgreSQL.properties
# returns a address db query more then this threshold is result to inaccurate
max.street.count=10
# label name
node.location=Location
path.2.postags.file=D\:\\VMS\\postags\\de-posTags.txt
# center distance calculation 
origin.location.longitude=13.383068d
# min threshold  of a named entity recongnition (Poi finding) is term score less result will be discard   
min.probability=0.95d
path.2.sentence.tokenizer.file=D\:\\VMS\\trained_model\\de-token.bin
# should run keyword analyze
keyword.analyse=true
# seek pois by column name and column synonyms in db
contains.in.synonyms=false
# to avoid number overflow by in textrank algorithm
with.vector.normalization=true
path.2.sentence.detector.file=D\:\\VMS\\trained_model\\de-sent.bin
result.2.neo4j=true
# label name
node.address=Address
# useless
output.folder=D\:\\VMS\\output
# which catalogs (only these both)
keyword.filter.catalogs=de.citytwin.model.Term,de.citytwin.model.ALKIS
# name of center for distance calculation 
origin.location.name=Berlin
path.2.pos-tagger.file=D\:\\VMS\\trained_model\\de-pos-maxent.bin
# label name
edge.contains=contains
path.2.stopwords.file=D\:\\VMS\\stopwords\\de-stopswords.txt
# useless
working.folder=D\:\\documents\\working
# geonames api parameter 
geonames.CountryCode=de
# threshold of result items by word2vec (List<String))
max.nearest=10
# name zip entry in geoname dump (contains several)
geonames.zip.entry=DE.txt
# textrank and tf ifd use stemming?
with.stemming=false
# label name
node.term=Term
node.document=Document
node.alkis=ALKIS
path.2.Term.catalog.file=D\:\\VMS\\catalogs\\ct_terms_catalog.json
# regex patter for address seek in textcorpus 
address.regex=([A-Z][ a-z\u00E4\u00FC\u00F6\u00DF-]+)+(\\. | |\\.|)(?>(\\d{1,3})(([a-zA-Z-/]{0,2})\\d{0,3}[a-zA-Z]?))
# uri 
geonames.url.2.dump.file=https\://download.geonames.org/export/dump/DE.zip
# regex patter for characters to remove in textcorpus 
cleaning.regex=[^\\u2013\\u002D\\w\u00E4\u00C4\u00F6\u00D6\u00FC\u00DC\u00DF,-/]
# word2vec parameter, lesser --> more results and less accurate  | greater --> lesser results and greater accurate 
similarity=66
# label name
edge.belongsTo=belongsTo
# textrank parameter 
iteration=10
path.2.keepwords.file=D:\\VMS\\keepwords\\de-keepwords.txt
# threshold distance calculation (greater result will be discard)
max.distance.in.meters=12500.0d
# label name
node.keyword=Keyword
word.window.size=5
# geonames parameter
geonames.user=demo
# threshold how many newlines are allowed in a text segment (table of content probability calculation)
max.newlines=5
#threshold  for table of content probability calculation in percent | greater result will be discard 
min.table.of.Content=95
result.2.postgreSQL=false
path.2.ner.location.file=D\:\\VMS\\trained_model\\de-ner-location_maxent.bin
named.entity.analyse=true
# threshold of a single term length (String.length)
min.term.length=5
postgreSQL.uri=jdbc\:postgresql\://83.135.47.253/citytwin
neo4j.uri=bolt\://localhost\:7687
# use stopword filter in textRank and tf idf 
with.stopword.filter=false
#path.2.word2vec.file=D\:\\VMS\\trained_model\\word2vecnewTrained.bin
path.2.word2vec.file=D\:\\VMS\\trained_model\\word2vec_2021-10-28.bin
# threshold, textsegment have to contain this count of terms (Helle world) --> remove (table of content calculation)
min.term.count=2
neo4j.user=neo4j